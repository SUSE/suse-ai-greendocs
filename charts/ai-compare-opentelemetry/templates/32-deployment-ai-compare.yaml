apiVersion: apps/v1
kind: Deployment
metadata:
  name: {{ include "ai-compare-opentelemetry.fullname" . }}-app
  annotations:
    configmap.dependency/demo-config: "{{ include "ai-compare-opentelemetry.fullname" . }}-demo-config"
    configmap.dependency/critical: "true"
    observability.suse.com/configmap-monitor: "{{ include "ai-compare-opentelemetry.fullname" . }}-demo-config"
    description: "CRITICAL: This deployment depends on demo-config ConfigMap for availability demo functionality"
    # GenAI Application Annotations for SUSE Observability
    genai.observability/enabled: "true"
    genai.observability/type: "chat-application"
    genai.observability/models: "llama3.2:latest"
    genai.observability/framework: "ollama"
    observability.suse.com/genai-app: "true"
    ai.application.category: "conversational-ai"
  labels:
    configmap.dependency: "demo-config-critical"
    app.kubernetes.io/name: {{ include "ai-compare-opentelemetry.name" . }}
    app.kubernetes.io/instance: {{ .Release.Name }}
    app.kubernetes.io/component: genai-chat
    app.kubernetes.io/part-of: genai-stack
    ai.framework: "gradio-ollama"
    genai.application: "true"
    genai.app: "true"
spec:
  replicas: 1
  selector:
    matchLabels:
      app: {{ include "ai-compare-opentelemetry.fullname" . }}-app
  template:
    metadata:
      annotations:
        configmap.dependency/demo-config: "{{ include "ai-compare-opentelemetry.fullname" . }}-demo-config"
        configmap.dependency/required: "true"
        suse.observability/monitor-configmap: "{{ include "ai-compare-opentelemetry.fullname" . }}-demo-config"
        pod.description: "Pod requires demo-config ConfigMap for availability demo - monitor ConfigMap changes"
      labels:
        app: {{ include "ai-compare-opentelemetry.fullname" . }}-app
        configmap.dependency: "demo-config-critical"
        observability.target: "configmap-monitoring"
    spec:
      serviceAccountName: ai-compare-service-account
      {{- with .Values.imagePullSecrets }}
      imagePullSecrets:
        {{- toYaml . | nindent 8 }}
      {{- end }}
      containers:
        - name: app
          image: "{{ .Values.aiCompare.image.repository }}:{{ .Values.aiCompare.image.tag }}"
          imagePullPolicy: {{ .Values.imagePullPolicy }}
          ports:
            - containerPort: {{ .Values.aiCompare.service.port }}
              name: gradio
            - containerPort: {{ .Values.aiCompare.httpApi.port }}
              name: http-api
          env:
            - name: OLLAMA_BASE_URL
              value: "http://ollama-service:11434"
            - name: OPEN_WEBUI_BASE_URL
              value: "http://open-webui-service:8080"
            # Pipeline service configuration
            - name: PIPELINES_BASE_URL
              value: "http://pipelines-service:9099"
            - name: PIPELINE_API_KEY
              value: "{{ .Values.pipelines.autoConfig.apiKey }}"
            # --- NEW ENVIRONMENT VARIABLES ---
            - name: AUTOMATION_ENABLED
              value: "{{ .Values.aiCompare.automation.enabled }}"
            - name: AUTOMATION_PROMPT
              value: "{{ .Values.aiCompare.automation.defaultPrompt }}"
            - name: AUTOMATION_INTERVAL
              value: "{{ .Values.aiCompare.automation.intervalSeconds }}"
            - name: AUTOMATION_SEND_MESSAGES
              value: "{{ .Values.aiCompare.automation.sendMessages }}"
            # Observability configuration (enhanced for OpenTelemetry edition)
            - name: OBSERVABILITY_ENABLED
              value: "{{ .Values.aiCompare.observability.enabled }}"
            - name: OTLP_ENDPOINT
              value: "{{ .Values.aiCompare.observability.otlpEndpoint }}"
            - name: COLLECT_GPU_STATS
              value: "{{ .Values.aiCompare.observability.collectGpuStats }}"
            # Force development mode for OpenLit instrumentation
            - name: DEV_MODE
              value: "true"
            # Add working genai app environment pattern
            - name: OLLAMA_ENDPOINT
              value: "http://ollama-service:11434"
            # Enhanced GenAI observability settings
            - name: TOKEN_TRACKING_ENABLED
              value: "{{ .Values.aiCompare.observability.tokenTracking }}"
            - name: COST_TRACKING_ENABLED
              value: "{{ .Values.aiCompare.observability.costTracking }}"
            - name: MODEL_METRICS_ENABLED
              value: "{{ .Values.aiCompare.observability.modelMetrics }}"
            - name: TRACE_REQUESTS_ENABLED
              value: "{{ .Values.aiCompare.observability.traceRequests }}"
            # Clean OpenLit configuration (following ravan/llm-experiments pattern)
            # (COLLECT_GPU_STATS and OLLAMA_ENDPOINT already defined above)
            # Model configuration for demo
            - name: MODEL_CONFIG
              valueFrom:
                configMapKeyRef:
                  name: ai-compare-config
                  key: MODEL_CONFIG
            - name: CONFIG_MAP_NAME
              value: "ai-compare-config"
            - name: CONFIG_MAP_NAMESPACE
              value: "{{ .Release.Namespace }}"
            # Service health failure simulation
            - name: SERVICE_HEALTH_FAILURE
              value: "false"
            - name: DEPLOYMENT_NAME
              value: "{{ include "ai-compare-opentelemetry.fullname" . }}-app"
            # HTTP API configuration
            - name: HTTP_API_ENABLED
              value: {{ .Values.aiCompare.httpApi.enabled | quote }}
            - name: HTTP_API_PORT
              value: {{ .Values.aiCompare.httpApi.port | quote }}
            - name: DEMO_CONFIG_PATH
              value: "/app/demo-config"
            # Demo ConfigMap manipulation settings
            - name: KUBERNETES_NAMESPACE
              value: "{{ .Release.Namespace }}"
            # CRITICAL: ConfigMap dependency for availability demo
            - name: DEMO_CONFIGMAP_NAME
              value: "{{ include "ai-compare-opentelemetry.fullname" . }}-demo-config"
            - name: DEMO_CONFIGMAP_CRITICAL
              value: "true"
            # Timeout configuration for SUSE security policy compatibility
            - name: CONNECTION_TIMEOUT
              value: "5"
            - name: REQUEST_TIMEOUT
              value: "8"
            - name: INFERENCE_TIMEOUT
              value: "60"
            # Enable mock mode for reliable telemetry generation
            - name: GENAI_MOCK_MODE
              value: "true"
            # Required Kubernetes environment variables for resource attributes
            - name: K8S_POD_NAME
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name
            - name: K8S_POD_UID
              valueFrom:
                fieldRef:
                  fieldPath: metadata.uid
            - name: K8S_NODE_NAME
              valueFrom:
                fieldRef:
                  fieldPath: spec.nodeName
            # Simplified OpenTelemetry resource attributes - let OpenLit handle GenAI semantic conventions
            - name: OTEL_RESOURCE_ATTRIBUTES
              value: >-
                service.namespace={{ .Release.Namespace }},service.version=1.0.0,service.instance.id=$(K8S_POD_UID),
                deployment.environment={{ .Release.Namespace }},k8s.namespace.name={{ .Release.Namespace }},
                k8s.pod.name=$(K8S_POD_NAME),k8s.pod.uid=$(K8S_POD_UID),k8s.node.name=$(K8S_NODE_NAME)
            # Explicit service name configuration (matching working genai apps pattern)
            - name: OTEL_SERVICE_NAME
              value: "AICompareGenerator"
            # Add APP_NAME like working genai apps (match exact pattern)
            - name: APP_NAME
              value: "AICompareGenerator"
            # OpenTelemetry service configuration overrides
            {{- if .Values.aiCompare.env }}
            {{- range $key, $value := .Values.aiCompare.env }}
            {{- if eq $key "OTEL_SERVICE_NAMESPACE" }}
            - name: {{ $key }}
              value: {{ $.Release.Namespace | quote }}
            {{- else if ne $key "OTEL_SERVICE_NAME" }}
            - name: {{ $key }}
              value: {{ $value | quote }}
            {{- end }}
            {{- end }}
            {{- end }}
          # Health checks to ensure proper startup sequencing
          livenessProbe:
            httpGet:
              path: /health
              port: {{ .Values.aiCompare.httpApi.port }}
            initialDelaySeconds: 15
            periodSeconds: 10
            timeoutSeconds: 5
            failureThreshold: 3
          readinessProbe:
            httpGet:
              path: /health
              port: {{ .Values.aiCompare.httpApi.port }}
            initialDelaySeconds: 10
            periodSeconds: 5
            timeoutSeconds: 3
            successThreshold: 1
            failureThreshold: 3
          volumeMounts:
            - name: config-volume
              mountPath: /app/config.json
              subPath: config.json
            - name: config-volume
              mountPath: /app/pricing.json
              subPath: pricing.json
            - name: demo-config-volume
              mountPath: /app/demo-config
              readOnly: true
          resources:
            {{- toYaml .Values.aiCompare.resources | nindent 12 }}
      volumes:
        - name: config-volume
          configMap:
            name: app-config
        - name: demo-config-volume
          configMap:
            name: {{ include "ai-compare-opentelemetry.fullname" . }}-demo-config
